\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{unicode=true,
            pdftitle={Statistical Data Science in Action},
            colorlinks=true,
            linkcolor=Maroon,
            citecolor=Blue,
            urlcolor=blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Statistical Data Science in Action}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \subtitle{Experiencing Realworld Data Analytics}
  \author{Jun Yan\\
Department of Statistics\\
University of Connecticut}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{January 22, 2019}

\newcommand{\E}{\mathbb{E}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\bx}{\textbf{x}}
\newcommand{\bX}{\textbf{X}}
\newcommand{\bz}{\textbf{z}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bPsi}{\boldsymbol{\Psi}}
\newcommand{\chunksize}{\fontsize{7.6pt}{8pt}\selectfont}

\begin{document}
\maketitle

\subsection{Preliminaries}\label{preliminaries}

\begin{itemize}
\tightlist
\item
  R: SIAM workshop on R by Wenjie Wang

  \begin{itemize}
  \tightlist
  \item
    \href{https://wenjie-stat.me/2018-01-19-siam/}{session one};
    \href{https://github.com/wenjie2wang/2018-01-19-siam/}{source repo}
  \item
    \href{https://wenjie-stat.me/2018-04-06-siam/}{session two};
    \href{https://github.com/wenjie2wang/2018-04-06-siam/}{source repo}
  \end{itemize}
\item
  Python

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.youtube.com/watch?v=N4mEzFDjqtA}{Learning Python
    in one video}
  \end{itemize}
\item
  Bookdown by Yihui Xie

  \begin{itemize}
  \tightlist
  \item
    \href{https://github.com/rstudio/bookdown}{R package source}
  \item
    \href{https://bookdown.org/yihui/bookdown/}{online book}
  \end{itemize}
\item
  Git/GitHub

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.youtube.com/watch?v=Y9XZQO1n_7c}{Learn Git in 20
    minues}
  \end{itemize}
\end{itemize}

\subsection{R Packages}\label{r-packages}

\bigskip\chunksize

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{##' Load needed packages, and install them if not installed.}
\NormalTok{##'}
\NormalTok{##' @usage need.packages(pkg)}
\NormalTok{##' @param pkg A character vector specifying the packages needed to}
\NormalTok{##'     reproduce this document.}
\NormalTok{##' @param ... Other arguments passed to function}
\NormalTok{##'     \textbackslash{}code\{\textbackslash{}link[base]require\}.}
\NormalTok{##' @return \textbackslash{}code\{NULL\} invisibly.}
\NormalTok{##' @examples}
\NormalTok{##' need.pacakges(c("ggplot2", "geepack"))}
\NormalTok{need.packages <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(pkg, ...)}
\NormalTok{\{}
\NormalTok{    new.pkg <-}\StringTok{ }\NormalTok{pkg[}\OperatorTok{!}\StringTok{ }\NormalTok{(pkg }\OperatorTok{%in%}\StringTok{ }\KeywordTok{installed.packages}\NormalTok{()[, }\StringTok{"Package"}\NormalTok{])]}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{length}\NormalTok{(new.pkg))}
        \KeywordTok{install.packages}\NormalTok{(new.pkg, }\DataTypeTok{repos =} \StringTok{"https://cloud.r-project.org"}\NormalTok{)}
\NormalTok{    foo <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(a, ...) }\KeywordTok{suppressMessages}\NormalTok{(}\KeywordTok{require}\NormalTok{(a, ...))}
    \KeywordTok{sapply}\NormalTok{(pkg, foo, }\DataTypeTok{character.only =} \OtherTok{TRUE}\NormalTok{)}
    \KeywordTok{invisible}\NormalTok{(}\OtherTok{NULL}\NormalTok{)}
\NormalTok{\}}
\NormalTok{pkgs <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"bookdown"}\NormalTok{, }\StringTok{"revealjs"}\NormalTok{)}
\KeywordTok{need.packages}\NormalTok{(pkgs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'bookdown' was built under R version 3.5.2
\end{verbatim}

\begin{verbatim}
## Warning: package 'revealjs' was built under R version 3.5.2
\end{verbatim}

\normalsize

\subsection{Motivation}\label{motivation}

\begin{itemize}
\item
  Hands on realworld data analytics
\item
  Tools for analytics as well as tools for project management
\item
  Workflow ensuring reproducibility
\item
  Version control
\item
  Learning on the fly
\item
  Communications (oral, written, critical review, etc.)
\item
  Data science competitions / data challenges
\end{itemize}

\subsection{Operation}\label{operation}

\begin{itemize}
\item
  Instructor is a coach
\item
  Everyone is both an instructor, a learner, and a reviewer
\item
  Projects (training/real; group/individual; common/open; repository)
\item
  Peer review like a journal review system
\item
  Open source book on data science in action
\item
  Guest lecturers
\item
  Outreach (partnership with CT Open Data, CT Data Collaborative, etc.)
\item
  Google
\end{itemize}

\subsection{Topics}\label{topics}

\begin{itemize}
\item
  Clusterd data analysis (GEE, copulas, NLME)
\item
  Causal inference
\item
  Deep learning
\item
  Propensity score
\end{itemize}

\section{Preliminaries: Statistical and Causal
Models}\label{preliminaries-statistical-and-causal-models}

\subsection{Simpson's Paradox}\label{simpsons-paradox}

\begin{itemize}
\item
  Edward Simpson (1951, JRSSb)
\item
  A statistical association that holds for an entire population is
  reversed in every subpopulation.
\item
  Table 1.1 Results of a study into a new drug, with gender being taken
  into account
\item
  The reason the drug appears to be harmful overall is that, if we
  select a drug user at random, that person is more likely to be a woman
  and hence less likely to recover than a random person who does not
  take the drug.
\item
  Put differently, being a woman is a common cause of both drug taking
  and failure to recover.
\end{itemize}

\subsection{Simpson's Paradox: Continuous
varaible}\label{simpsons-paradox-continuous-varaible}

\begin{itemize}
\item
  Figure 1.1 Results of the exerciseâ``cholesterol study, segregated by
  age
\item
  However, segregated data does not always give the correct answer.
\item
  Suppose we looked at the same numbers from our first example of drug
  taking and recovery, instead of recording participantsâ gender,
  patientsâ blood pressure were recorded at the end of the experiment.

  \begin{itemize}
  \tightlist
  \item
    the drug affects recovery by lowering the blood pressure of those
    who take itâbut unfortunately, it also has a toxic effect.
  \item
    would you recommend the drug to a patient?
  \end{itemize}
\end{itemize}

\subsection{Segregated data does not always give the correct
answer}\label{segregated-data-does-not-always-give-the-correct-answer}

\begin{itemize}
\item
  Table 1.2 Results of a study into a new drug, with posttreatment blood
  pressure taken into account
\item
  Since lowering blood pressure is one of the mechanisms by which
  treatment affects recovery, it makes no sense to separate the results
  based on blood pressure.
\item
  So we consult the results for the general population, we find that
  treatment increases the probability of recovery, and we decide that we
  should recommend treatment.
\item
  None of the information that allowed us to make a treatment
  decisionânot the timing of the measurements, not the fact that
  treatment affects blood pressure, and not the fact that blood pressure
  affects recoveryâwas found in the data.
\item
  Trivial though the assumption âtreatment does not cause sexâ may
  seem, there is no way to test it in the data, nor is there any way to
  represent it in the mathematics of standard statistics.
\end{itemize}

\subsection{A calculus of causation}\label{a-calculus-of-causation}

In order to rigorously approach our understanding of the causal story
behind data, we need four things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A working definition of âcausation.â
\item
  A method by which to formally articulate causal assumptionsâthat is,
  to create causal models.
\item
  A method by which to link the structure of a causal model to features
  of data.
\item
  A method by which to draw conclusions from the combination of causal
  assumptions embedded in a model and data.
\end{enumerate}

A variable \(X\) is a cause of a variable \(Y\) if \(Y\) in any way
relies on X for its value.

\subsection{Graph}\label{graph}

\begin{itemize}
\item
  Graph theory provides a useful mathematical language that allows us to
  address problems of causality with simple operations similar to those
  used to solve arithmetic problems.
\item
  A mathematical graph is a collection of \emph{vertices} (or, as we
  will call them, \emph{nodes}) and \emph{edges}.
\item
  Two nodes are \emph{adjacent} if there is an edge between them.
\item
  \emph{complete graph}
\item
  \emph{path} between two nodes
\item
  directed vs undirected
\item
  parent vs child
\item
  ancester vs descendant
\item
  cyclic vs acyclic
\end{itemize}

\subsection{Structural causal model}\label{structural-causal-model}

\begin{itemize}
\item
  A structural causal model consists of two sets of variables \(U\) and
  \(V\), and a set of functions \(f\) that assigns each variable in
  \(V\) a value based on the values of the other variables in the model.
\item
  A variable \(X\) is a direct cause of a variable \(Y\) if \(X\)
  appears in the function that assigns \(Y\)âs value. \(X\) is a cause
  of \(Y\) if it is a direct cause of \(Y\),or of any cause of \(Y\).
\item
  exogenous vs endogenous
\item
  root node
\item
  Every SCM is associated with a graphical causal model, referred to
  informally as a âgraph- ical modelâ or simply âgraph.â
\item
  We will deal primarily with SCMs for which the graphical models are
  directed acyclic graphs (DAGs).
\end{itemize}

\subsection{Product decomposition}\label{product-decomposition}

\begin{itemize}
\tightlist
\item
  Rule of product decomposition: For any model whose graph is acyclic,
  the joint distribution of the variables in the model is given by the
  product of the conditional distributions \(P(child \mid parents)\)
  over all the âfamiliesâ in the graph. Formally, we write this rule
  as \[
  P(x_1, x_2, \ldots , x_n) = \prod_i P(x_i | pa_i)
  \] where \(pa_i\) stands for the values of the parents of variable
  \(X_i\).
\end{itemize}

\section{Graphical Models and Their
Applications}\label{graphical-models-and-their-applications}

\subsection{Connecting Models to Data}\label{connecting-models-to-data}

\begin{itemize}
\item
  Probabilities, graphs, structural equations
\item
  The concept of independence, which in the language of probability is
  defined by alge braic equalities, can be expressed visually using
  directed acyclic graphs (DAGs).
\item
  Further, this graphical representation will allow us to capture the
  probabilistic information that is embedded in a structural equation
  model.
\item
  Shoule be able to predict patterns of independencies in the data,
  based solely on the structure of the modelâs graph, without relying
  on any quantitative information carried by the equations or by the
  distributions of the errors
\end{itemize}

\subsection{Chains}\label{chains}

\begin{itemize}
\item
  Figure 2.1

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(Z\) and \(Y\) are dependent
  \item
    \(Y\) and \(X\) are dependent
  \item
    \(Z\) and \(X\) are likely dependent
  \item
    \(Z\) and \(X\) are independent, conditional on \(Y\)
  \end{enumerate}
\item
  SCM 2.2.4 Pathological Case of Intransitive Dependence
\item
  This configuration of variables --- three nodes and two edges, with
  one edge directed into and one edge directed out of the middle
  variable --- is called a \emph{chain}.
\item
  \textbf{Rule 1 (Conditional Independence in Chains)} Two variables,
  \(X\) and \(Y\), are conditionally independent given \(Z\), if there
  is only one unidirectional path between \(X\) and \(Y\) and \(Z\) is
  any set of variables that intercepts that path.
\end{itemize}

\subsection{Forks}\label{forks}

\begin{itemize}
\item
  Figure 2.2

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(X\) and \(Y\) are dependent
  \item
    \(X\) and \(Z\) are dependent
  \item
    \(Z\) and \(Y\) are likely dependent
  \item
    \(Y\) and \(Z\) are independent, conditional on \(Y\)
  \end{enumerate}
\item
  Why are \(Y\) and \(Z\) independent conditional on X?
\item
  This configuration of variables --- three nodes, with two arrows
  emanating from the middle variable --- is called a \emph{fork}.
\item
  \textbf{Rule2 (Conditional Independence in Forks)} If a variable \(X\)
  is a common cause of variables \(Y\) and \(Z\), and there is only one
  path between \(Y\) and \(Z\), then \(Y\) and \(Z\) are independent
  conditional on \(X\)
\end{itemize}

\subsection{Colliders}\label{colliders}

\begin{itemize}
\item
  Figure 2.3

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(X\) and \(Z\) are dependent
  \item
    \(Y\) and \(Z\) are dependent
  \item
    \(X\) and \(Y\) are independent
  \item
    \(X\) and \(Y\) are dependent conditional on \(Z\)
  \end{enumerate}
\item
  A \emph{collider} node occurs when one node receives edges from two
  other nodes.
\item
  Why does point 4 hold? Conditioning on a collision node produces a
  dependence between the nodeâs parents
\item
  Monty Hall problem
\item
  \textbf{Rule 3 (Conditional Independence in Colliders)} If a variable
  \(Z\) is the collision node between two variables \(X\) and \(Y\), and
  there is only one path between \(X\) and \(Y\), then \(X\) and \(Y\)
  are unconditionally independent but are dependent conditional on \(Z\)
  and any descendants of \(Z\)
\end{itemize}

\subsection{\texorpdfstring{\(d\)-separation}{d-separation}}\label{d-separation}

\begin{itemize}
\item
  Is there a criterion or process that can be applied to a graphical
  causal model of any complexity in order to predict dependencies that
  are shared by all data sets generated by that graph?
\item
  A pair of nodes are \(d\)-connected if there exists a connecting path
  between them, or \(d\)-separated, if there exists no such path.
\item
  When we say that a pair of nodes are \(d\)-separated, we mean that the
  variables they represent are definitely independent; when we say that
  a pair of nodes are \(d\)-connected, we mean that they are possibly,
  or most likely, dependent.
\item
  Two nodes are \(d\)-separated if every path between them (should any
  exist) is blocked.
\item
  The paths between variables can be thought of as pipes, and dependence
  as the water that flows through them; if even one pipe is unblocked,
  some water can pass from one place to another, and if a single path is
  clear, the variables at either end will be dependent. However, a pipe
  need only be blocked in one place to stop the flow of water through
  it, and similarly, it takes only one node to block the passage of
  dependence in an entire path.
\end{itemize}

\subsection{Nodes that can block a
path}\label{nodes-that-can-block-a-path}

\begin{itemize}
\item
  If we are not conditioning on any variable, then only colliders can
  block a path.
\item
  If, however, we are conditioning on a set of nodes \(Z\), then the
  following kinds of nodes can block a path:

  \begin{itemize}
  \tightlist
  \item
    A collider that is not conditioned on (i.e., not in \(Z\)), and that
    has no descendants in \(Z\)
  \item
    A chain or fork whose middle node is in \(Z\).
  \end{itemize}
\item
  Definition 2.4.1 (\(d\)-separation)
\item
  Example, Figure 2.7
\end{itemize}

\subsection{Model testing}\label{model-testing}

\begin{itemize}
\item
  \(d\)-separation will tell us which variables in \(G\) must be
  independent conditional on which other variables. Conditional
  independence is something we can test for using a data set.
\item
  Example, Figure 2.9

  \begin{itemize}
  \tightlist
  \item
    Not only we know that the model is wrong, but we also know where it
    is wrong; the true model must have a path between \(W\) and \(Z_1\)
    that is not \(d\)-separated by \(X\)
  \item
    Finally, this is a theoretical result that holds for all acyclic
    models with independent errors (Verma and Pearl 1990), and we also
    know that if every d-separation condition in the model matches a
    conditional independence in the data, then no further test can
    refute the model. This means that, for any data set whatsoever, one
    can always find a set of functions F for the model and an assignment
    of probabilities to the U terms, so as to generate the data
    precisely.
  \end{itemize}
\end{itemize}

\subsection{Causal search}\label{causal-search}

\begin{itemize}
\item
  \(d\)-separation presents several advantages over the global testing
  method

  \begin{itemize}
  \tightlist
  \item
    nonparametric
  \item
    local test
  \end{itemize}
\item
  could test and reject many possible models in this way, even- tually
  whittling down the set of possible models to only a few whose testable
  implications do not contradict the dependencies present in the data
  set.
\item
  some graphs have indistinguishable implication
\item
  allows us to search a data set for the causal models that could have
  generated it.
\end{itemize}

\section{The Effects of
Interventions}\label{the-effects-of-interventions}

\subsection{Intervention}\label{intervention}

\begin{itemize}
\item
  Predict effects of interventions.
\item
  Correlation is not causation.
\item
  Randomized controlled experiment can solve this problem. But we can't
  control some factors. Then only observationsl study can be conducted,
  which is hard to untangle causal from merely correlative.
\item
  Intervene and condition are different. Intervene changes the model
  structure, but condition doesn't. (Figure 3.2)
\item
  \(do\)-expression and graph surgery can help solve this problem.
\end{itemize}

\subsection{The Adjustment Formula}\label{the-adjustment-formula}

\begin{itemize}
\item
  Causal effect; adjusting for Z or controlling for Z.
\item
  Example: Simpson's paradox, Figure 3.3, 3.4.
\end{itemize}

\subsubsection{To Adjust or not?}\label{to-adjust-or-not}

\begin{itemize}
\item
  \textbf{Rule 1 (The Causal Effect Rule)} Given a graph G in which a
  set of variables PA are designated as the parents of X, the causal
  effect of X on Y is given by \[
  P(Y = y|do(X = x)) = \sum_z P(Y = y|X = x, PA = z)P(PA = z)
  \] where z ranges over all the combinations of values that the
  variables in PA can take. If we multiply and divide the right hand
  side by the probability \(P(X = x|PA = z)\), we get a more convenient
  form: \[
  P(y|do(x)) = \sum_z \frac{P(X = x, Y = y, PA = z)}{P(X = x|PA = z)}
  \]
\item
  It is possible to use graphs and underlying assumptions, we are able
  to identify causal relationships in purely obervational data.
\item
  In most practical cases, the set of Xâs parents (PA(X)) will contain
  unobserved variables that would prevent us from calculating the
  conditional probabilities in the adjustment formula. Solution: adjust
  other variables to substitute for the unmeasured elements of PA(X).
\end{itemize}

\subsubsection{Multiple Interventions and the Truncated Product
Rule}\label{multiple-interventions-and-the-truncated-product-rule}

\begin{itemize}
\item
  \emph{Truncated product formula} or \emph{g-formula}: \[
  P(x_1, x_2, \dots, x_n|do(x)) = \prod_i P(x_i|pa_i)
  \] for all \(X_1, X_2, \dots, X_n\) not in \(X\).
\item
  \[ P(x_1, x_2, \dots, x_n|do(x)) = \frac{P(x_1, x_2, \dots, x_n, x)}{P(x|pa)} 
  \]
\end{itemize}

\subsection{The Backdoor Criterion}\label{the-backdoor-criterion}

\begin{itemize}
\item
  Under what conditions, is the structure of the causal graph sufficient
  for computing a causal effect from a given data set? The rest of this
  chapter will focuse on this problem.
\item
  \textbf{The Backdoor Criterion} Given an ordered pair of variables
  (X,Y) in a directed acyclic graph G, a set of variables Z satisfies
  the backdoor criterion relative to (X, Y) if no node in Z is a
  descendant of X, and Z blocks every path between X and Y that contains
  an arrow into X. (when conditioned on Z)
\item
  If a set of variables Z satisfies the backdoor criterion for X and Y,
  then the causal effect of X on Y is given by the formula: \[
  P(Y = y|do(X = x)) = \sum_z P(Y = y|X = x, Z = z)P(Z = z)
  \] just as when we adjust for PA(X). (Note that PA(X) always satisfies
  the backdoor criterion.) Example Figure 3.3
\item
  In general, we would like to condition on a set of nodes Z such that
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We block all spurious paths between X and Y.
\item
  We leave all directed paths from X to Y unperturbed.
\item
  We create no new spurious paths.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \emph{Effect modification} or \emph{moderation}. Find the causal
  effect when we condition on some variable. Example, Figure 2.8; 3.6.
\end{itemize}

\subsection{The Front-Door Criterion (Example, Smoking and Lung
Cancer)}\label{the-front-door-criterion-example-smoking-and-lung-cancer}

\begin{itemize}
\tightlist
\item
  \textbf{Front-Door} A set of variables Z is said to satisfy the
  front-door criterion relative to an ordered pair of variables (X, Y)
  if
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Z intercepts all directed paths from X to Y.
\item
  There is no unblocked path from X to Z.
\item
  All backdoor paths from Z to Y are blocked by X.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \textbf{Front-Door Adjustment} If Z satisfies the front-door criterion
  relative to (X, Y) and if \(P(x, z) > 0\), then the causal effect of X
  on Y is identifiable and is given by the formula: \[
  P(y|do(x)) = \sum_z P(z|x) \sum_{x'} P(y|x', z)P(x')
  \]
\end{itemize}

\subsection{Conditional Interventions and Covariate-Specific
Effects}\label{conditional-interventions-and-covariate-specific-effects}

\begin{itemize}
\item
  Interventions may involve dynamic policies in which a variable X is
  made to respond in a specified way to some set Z of other
  variablesâsay, through a functional relationship \(x = g(z)\) or
  through a stochastic relationship, whereby X is set to x with
  probability \(P^*(x|z)\).
\item
  The result of implementing such a policy is a probability distribution
  written \(P(Y = y|do(X = g(Z)))\), which depends only on the function
  \(g\) and the set \(Z\) of variables that drive \(X\).
\item
  \textbf{Rule 2} The z-specific effect \(P(Y = y|do(X = x), Z = z)\) is
  identified whenever we can measure a set S of variables such that
  \(S \cup Z\) satisfies the backdoor criterion. Moreover, the
  z-specific effect is given by the following adjustment formula: \[
  P(Y = y|do(X = x), Z = z) = \sum_s P(Y = y|X = x, S = s, Z = z)P(S = s|Z = z)
  \]
\item
  To compute \(P(Y = y|do(X = g(Z)))\), we condition on \(Z = z\) and
  write:

  \begin{equation*}
  \begin{split}
  P(Y = y|do(X = g(Z))) &= \sum_z P(Y = y|do(X = g(Z)), Z = z)P(Z = z|do(X = g(Z)))\\
                    &= \sum_z P(Y = y|do(X = g(z)), Z = z)P(Z = z)\\
                    &= \sum_z P(Y = y|do(X = x),z)|_{x=g(z)}P(Z = z)
  \end{split}
  \end{equation*}
\end{itemize}

\subsection{Inverse Probability
Weighing}\label{inverse-probability-weighing}

\begin{itemize}
\item
  Practical difficulties: adjusting for Z but Z contains too many
  variables.
\item
  Assuming that the function \(P(X = x|Z = z)\) is available to us, we
  can use it to generate artificial samples that act as though they were
  drawn from the postintervention probability \(P_m\), rather than
  \(P(x, y, z)\).
\item
  \begin{equation*}
  \begin{split}
  P(y|do(x)) &= \sum_z P(Y = y|X = x, Z = z)P(Z = z)\\
         &= \sum_z \frac{P(Y = y|X = x, Z = z)P(X = x|Z = z)P(Z = z)}{P(X = x|Z = z)}\\
         &= \sum_z \frac{P(X = x, Y = y, Z = z)}{P(X = x|Z = z)}
  \end{split}
  \end{equation*}
\end{itemize}

\subsection{Mediation}\label{mediation}

\begin{itemize}
\item
  Causation: direct and indirect (through mediating variables).
\item
  Seperate direct and indirect effects: condition on mediating
  variables. Example, Figure 3.11, 3.12
\item
  Intervene. For any three variables \(X\), \(Y\), and \(Z\), where
  \(Z\) is a mediator between \(X\) and \(Y\), \emph{Controlled direct
  effect} (CDE) on \(Y\) of changing the value of \(X\) from \(x\) to
  \(x'\) is defined as: \[
  CDE = P(Y = y|do(X = x), do(Z = z)) - P(Y = y|do(X = x'), do(Z = z))
  \] Example Figure 3.12.
\item
  In general, the CDE of \(X\) on \(Y\), mediated by \(Z\), is
  identifiable if the following two properties hold:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  There exists a set \(S_1\) of variables that blocks all backdoor paths
  from \(Z\) to \(Y\).
\item
  There exists a set \(S_2\) of variables that blocks all backdoor paths
  from X to Y, after deleting all arrows entering Z (intervene on Z).
\end{enumerate}

\subsection{Causal Inference in Linear
Systems}\label{causal-inference-in-linear-systems}

\begin{itemize}
\tightlist
\item
  Assumptions used in this section:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the relationships between variables are linear.
\item
  all error terms have Gaussian (or ânormalâ) distributions.
\end{enumerate}

\subsubsection{Structural versus Regression
Coefficients}\label{structural-versus-regression-coefficients}

\begin{itemize}
\item
  A regression equation is descriptive; it makes no assumptions about
  causation.
\item
  We use Greek letter (\(\alpha\), \(\beta\) and so on) for structural
  coefficients and \(r_i\) for regression coefficients. \(U_1\) for
  error term in structural equations and \(\epsilon_i\) for those in
  regression equations.
\end{itemize}

\subsubsection{The Causal Interpretation of Structural
Coefficients}\label{the-causal-interpretation-of-structural-coefficients}

\begin{itemize}
\item
  In a linear system, every path coefficient stands for the direct
  effect of the independent variable, \(X\), on the dependent variable,
  \(Y\).
\item
  In a linear system, the total effect of \(X\) on \(Y\) is simply the
  sum of the products of the coefficients of the edges on every
  nonbackdoor path from \(X\) to \(Y\). Example, Figure 3.13.
\end{itemize}

\subsubsection{Identifying Structural Coefficients and Causal
Effect}\label{identifying-structural-coefficients-and-causal-effect}

\begin{itemize}
\item
  Total effect: First, we find a set of covariates \(Z\) that satisfies
  the backdoor criterion from \(X\) to \(Y\) in the model. Then, we
  regress \(Y\) on \(X\) and \(Z\). The coefficient of \(X\) in the
  resulting equation represents the true causal effect of \(X\) on
  \(Y\). Example, Figure 3.14.
\item
  Direct effect: In a linear system, this direct effect is the
  structural coefficient \(\alpha\) in the function
  \(y = \alpha x + \beta z + \cdots + U_Y\) that defines \(Y\) in the
  system.
\item
  Direct effect (from data):
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  First, we remove the edge from \(X\) to \(Y\) (if such an edge
  exists), and call the resulting graph \(G_\alpha\). If, in
  \(G_\alpha\), there is a set of variables \(Z\) that d-separates \(X\)
  and \(Y\), then we can simply regress \(Y\) on \(X\) and \(Z\). The
  coefficient of \(X\) in the resulting equation will equal the
  structural coefficient \(\alpha\). Example, Figure 3.15, 3.16.
\item
  If there is no set of variables that \(d\)-separates \(X\) and \(Y\)
  in \(G_\alpha\), we can use total effects to identify direct effects.
  \emph{Instrumental variable}: it is \(d\)-separated from \(Y\) in
  \(G_\alpha\) and, it is \(d\)-connected to \(X\). Example, Figure
  3.17.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  To estimate a given effect, all we need to do is to write down a
  regression equation and specify:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  what variables should be included in the equation and
\item
  which of the coefficients in that equation represents the effect of
  interest.
\end{enumerate}

\section{Counterfactuals and Their
Applications}\label{counterfactuals-and-their-applications}

\subsection{Counterfactuals}\label{counterfactuals}

\begin{itemize}
\item
  While driving home last night, I came to a fork in the road, where I
  had to make a choice: to take the freeway (\(X\) = 1) or go on a
  surface street named Sepulveda Boulevard (\(X\) = 0). I took
  Sepulveda, only to find out that the traffic was touch and go. As I
  arrived home, an hour later, I said to myself: ``Gee, I should have
  taken the freeway.''
\item
  This kind of statement, an ``if'' statement in which the ``if''
  portion is untrue or unrealized is known as a counterfactual
\item
  The ``if'' portion of a counterfactual is called the hypothetical
  condition, or more often, the antecedent
\item
  We use counterfactuals to emphasize our wish to compare two outcomes
  under the exact same conditions while differing only in one aspect:
  the antecedent.
\item
  Writing
  \(\mathbb{E}[\text{driving time}|do(\text{freeway}), \text{driving time}=1 \text{ hour}]\)
  leads to a clash between the driving time we wish to estimate and
  actual driving time observed.
\end{itemize}

-To avoid clash, distinguish symbolically between:

\begin{verbatim}
1. Actual driving time
2. Hypothetical driving time under freeway conditions when actual surface driving time is known to be 1 hour
\end{verbatim}

\begin{itemize}
\item
  To do so, use different subscripts to label two outcomes

  \begin{itemize}
  \tightlist
  \item
    denote freeway driving time by \(Y_{X = 1}\) (or \(Y_1\))
  \item
    denote Sepulveda driving time by \(Y_{X = 0}\) (or \(Y_0\))
  \end{itemize}
\item
  Since \(Y_0\) is the \(Y\) actually observed, we wish to estimate
  \(\mathbb{E}[Y_{X=1}| X = 0, Y = Y_0 = 1]\).
\end{itemize}

\subsection{Defining and Computing
Counterfactuals}\label{defining-and-computing-counterfactuals}

\subsubsection{The Structural Interpretation of
Counterfactuals}\label{the-structural-interpretation-of-counterfactuals}

\begin{itemize}
\item
  Begin with fully specified model \(M\), for which functions \(\{F\}\)
  and values of exogenous variables are all known.
\item
  Simple causal model consisting of three variables: X, Y, U defined by:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(X = aU\)
  \item
    \(Y = bX + U\)
  \end{enumerate}
\item
  Computing the counterfactual \(Y_x(u)\), that is what \(Y\) would be
  had \(X\) been \(x\) in situation \(U = u\)
\item
  Replacing first equation with \(X = x\) gives ``modified'' model
  \(M_x\):

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \(X = x\)
  \item
    \(Y = bX + U\)
  \end{enumerate}
\item
  Substituting \(U = u\), and solving gives \$Y\_x(u) = bx + u
\item
  We can also examine counterfactual \(X_y(u)\), that is, what \(X\)
  would be had \(Y\) been \(y\) in situation \(U = u\).
\item
  Replacing second equation by constant \(Y = y\) and solving for \(X\),
  we have \(X_y(u) = au\), which means \(X\) remains unaltered by the
  hpothetical condition ``had \(Y\) been \(y\)''
\item
  Each SCM encodes within it many counterfactuals corresponding to
  various values its variables can take.
\item
  \(\textbf{Note}\): We compute not just the probability of expected
  value of \(Y\) under one intervention or another, but the
  \(\textbf{actual value of Y}\) under the hypothesized \(\textit{new}\)
  condition \(X = x\). Every structural equation model assigns a
  definitive value to every conceivable counterfactual.
\end{itemize}

\subsubsection{The Fundamental Law of
Counterfactuals}\label{the-fundamental-law-of-counterfactuals}

\begin{itemize}
\item
  Consider any arbitrary two variables \(X\) and \(Y\), not necessarily
  connected by a single equation. Let \(M_x\) stand for the modified
  version of \(M\), with the equation of \(X\) replaced by \(X = x\).
  The formal definition of the counterfactual \(Y_x(u)\) reads:

  \begin{equation}\label{eq:cf1}
  Y_x(u) = Y_{M_x}(u)
  \end{equation}
\item
  In words: The countervactual \(Y_x(u)\) in model \(M\) is defined as
  the solution for \(Y\) in the `surgically modified' submodel \(M_x\).
\item
  Eq.(\ref{eq:cf1}) is a fundamental principle of causal inference
  allowing us to answer questions of the type ``what would \(Y\) be had
  \(X\) been \(x\)?''
\item
  Counterfactuals obey the \(\textbf{consistency rule}\): \emph{if}
  \(X = x\) \emph{then} \(Y_x = Y\)

  \begin{itemize}
  \tightlist
  \item
    For example, if \(X\) is binary, then consistency rule takes form
    \(Y = XY_1 + (1 - X)Y_0\). This can be interpretted as \(Y_1\) is
    equal to the observed value of \(Y\) whenever \(X\) takes the value
    1.
  \end{itemize}
\end{itemize}

\subsubsection{From Population Data to Individual Behavior: An
Illustration}\label{from-population-data-to-individual-behavior-an-illustration}

\begin{itemize}
\item
  Fig. 4.1 represents an `encouragement design' (p.94)

  \begin{itemize}
  \tightlist
  \item
    \(X\) is amount of time a student spends in an after-school remedial
    program
  \item
    \(H\) is the amount of homework a student does
  \item
    \(Y\) is a student's score on exam
  \item
    Value of each variable is given as number of standard deviations
    above the mean the student falls
  \end{itemize}
\item
  Model 4.1:

  \begin{equation*}
  \begin{split}
    X &= U_X \\
    H &= aX + U_H \\
    Y &= bX + cH + U_Y \\
    \sigma_{U_i U_j} &=0 \quad \forall i,j \in \{X, H, Y\}
  \end{split}
  \end{equation*}
\item
  Assume all \(U\) factors are independent, and we are given the values
  of coefficients: \[a = 0.5, \quad b = 0.7, \quad c = 0.4\]
\item
  Consider Joe for whom we measure:
  \[X = 0.5, \quad H = 1, \quad Y = 1.5\]
\item
  We ask the question: `What would Joe's score have been had he doubled
  his study time?'

  \begin{itemize}
  \tightlist
  \item
    Use evidence \(X = 0.5, \quad H = 1, \quad Y = 1.5\) to determine
    the values of the \(U\) variables associated with Joe
  \item
    These values are invariant to hypothetical actions
  \end{itemize}
\item
  Obtaining the specific characteristics of Joe from evidence:

  \begin{equation*}
  \begin{split}
    U_X &= 0.5 \\
    U_H &= 1 - 0.5 \cdot 0.5 = 0.75 \\
    U_Y &= 1.5 - 0.7 \cdot 0.5 - 0.4 \cdot 1 = 0.75
  \end{split}
  \end{equation*}
\item
  Simulating the action of doubling Joe's study time by replacing the
  structural equation for \(H\) with the constant \(H = 2\) gives
  modified model in Fig. 4.2. (p.95). Compute the value of \(Y\) in
  modified model using updated \(U\) values.

  \begin{equation*}
  \begin{split}
    Y_{H=2}(U_X &= 0.5, U_H = 0.75, U_Y = 0.75) \\
    &= 0.5 \cdot 0.7 + 2.0 \cdot 0.4 + 0.75 \\
    &= 1.90
  \end{split}
  \end{equation*}

  \begin{itemize}
  \tightlist
  \item
    Had Joe doubled his homework, his score would have been 1.9 instead
    of 1.5
  \end{itemize}
\item
  In summary we applied evidence to update the values of the \(U\)
  variables, simulate external intervention to foce condition by
  replacing structural equation with constant, then compute value of
  \(Y\) given new structural equations and the updated \(U\) values.
\end{itemize}

\subsubsection{The Three Steps in Computing
Counterfactuals}\label{the-three-steps-in-computing-counterfactuals}

\begin{itemize}
\item
  The three-step process for computing any deterministic counterfactual:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Abduction: Use evidence \(E = e\) to determine the value of \(U\)
  \item
    Action: Modify the model, \(M\), by removing the structural
    equations for the variables in \(X\) and replacing them with the
    appropriate functions \(X = x\), to obtain the modified model,
    \(M_x\)
  \item
    Prediction: Use the modified model, \(M_x\), and the value of \(U\)
    to compute the value of \(Y\), the consequence of the counterfactual
  \end{enumerate}
\item
  The above process will solve any deterministic counterfactual, that
  is, counterfactuals pertaining to a single unit of the population in
  which we know the value of every relevant variable.
\item
  Counterfactuals can also be probabilistic, that is pertaining to a
  class of units within the population.

  \begin{itemize}
  \tightlist
  \item
    A typical query might be: `Given that we observe feature \(E = e\)
    for a given individual, what would we expect the value of \(Y\) for
    that individual to be if \(X\) had been \(x\)?'
  \item
    This expectation is denoted \(\mathbb{E}[Y_{X = x}|E = e]\), where
    \(E = e\) is allowed to conflict with the antecedent \(X = x\)
  \item
    We can generalize the three-step process to any probabilistic
    nonlinear system.
  \end{itemize}
\item
  Given an arbitrary counterfactuals of the form
  \(\mathbb{E}[Y_{X = x} | E = e]\), the three-step process reads:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Abduction: Update \(P(U)\) by the evidence to obtain \(P(U|E = e)\)
  \item
    Action: Modify the model, M, by removing the structural equations
    for the variables in \(X\) and replace them with the appropriate
    functions \(X = x\) to obtain the modified model \(M_x\)
  \item
    Use the modified model, \(M_x\), and the updated probabilities over
    the \(U\) variables, \(P(U|E = e)\), to compute the expectation of
    \(Y\), the consequence of the counterfactual
  \end{enumerate}
\end{itemize}

\subsection{Nondeterministic
Counterfactuals}\label{nondeterministic-counterfactuals}

\subsubsection{Probabilities of
Counterfactuals}\label{probabilities-of-counterfactuals}

\begin{itemize}
\item
  Refer to Eqs. (4.3) and (4.4) on p.~92
\item
  Imagine that \(U = \{1, 2, 3\}\) represents three types of individuals
  in a population, occurring with probabilities
  \[P(U = 1) = \frac{1}{2}, \quad P(U = 2) = \frac{1}{3}, \quad P(U = 3) = \frac{1}{6}\]
\item
  All individuals within a population type have the same values of the
  counterfactuals as specified by the rows in Table 4.1 (p.93). Using
  these values, it is possible to compute the probability that the
  counterfactual will satisfy a specific condition.
\item
  For example: We can compute the proportion of units for which \(Y\)
  would be 3 had \(X\) been 2, or using notation \(Y_2(u) = 3\).

  \begin{itemize}
  \tightlist
  \item
    Refer to table to see that \(P(Y_2 = 3) = \frac{1}{2}\)
  \item
    Using the table, how about \(P(Y_2 > 3)\)?
    \(\quad \quad \quad \quad \quad\) (Answer: \(\frac{1}{2}\))
  \end{itemize}
\item
  We can also compute joint probabilities of every combination of
  counterfactual and observable events:

  \begin{itemize}
  \tightlist
  \item
    For example: \(P(Y_2 > 3, Y_1 < 4) = \frac{1}{3}\)
  \item
    This is the joint probability of two events occurring in two
    different `worlds.' The firset \(Y_2 > 3\) in an \(X = 2\) world,
    and the second \(Y_1 < 4\) in an \(X = 1\) world.
  \item
    These joint probabilities over `multiple-world' counterfactuals are
    easily expressed using subscript notation, but \emph{cannot} be
    expressed using the \emph{do(x)} notation since the latter delivers
    a single probability for each intervention \(X = x\).
  \end{itemize}
\item
  We can also compute conditional probabilities among counterfactuals:

  \begin{itemize}
  \tightlist
  \item
    For example: Among the individuals for which \(Y\) is greater than
    2, the probability is \(\frac{2}{2}\) that \(Y\) would increase if
    \(X\) were 3 since
    \[P(Y_3 > Y | Y > 2) = \frac{\frac{1}{3}}{\frac{1}{2}} = \frac{2}{3}\]
  \end{itemize}
\item
  Example p.99
\item
  Can counterfactual notation capture the postintervention single-world
  expression \(\mathbb{E}[Y|do(X = x), Z = 1]\)?

  \begin{itemize}
  \tightlist
  \item
    Answer: Yes
  \item
    Translating \(\mathbb{E}[Y|do(X = x), Z = 1]\) into counterfactual
    notation yields \(\mathbb{E}[Y_{X=1}|Z_{X=1} = 1]\).

    \begin{itemize}
    \tightlist
    \item
      \(Z_{X=1}\) stands for the value that \(Z\) would attain had
      \(X = 1\)
    \end{itemize}
  \end{itemize}
\item
  Example p.~100
\end{itemize}

\subsubsection{The Graphical Representation of
Counterfactuals}\label{the-graphical-representation-of-counterfactuals}

\begin{itemize}
\item
  Can we see counterfactuals within the causal graphs associated with
  the model?

  \begin{itemize}
  \tightlist
  \item
    Yes!
  \item
    From the fundamental law of counterfactuals, Eq.(\ref{eq:cf1}), if
    we modeify model \(M\) to obtain the submodel \(M_x\), then the
    outcome variable \(Y\) in the modified model is the counterfactual
    \(Y_x\) of the original model
  \item
    This modification calls for removing all arrows entering the
    variable \(X\)
  \end{itemize}
\item
  \(\textbf{Theorem 4.3.1: Counterfactual Interpretation of Backdoor}\):
  If a set \(Z\) of variables satisfies the backdoor condition relative
  to \((X,Y)\), then, for all \(x\), the counterfactual \(Y_x\) is
  conditionally independent of \(X\) given \(Z\),
  \[P(Y_x|X,Z) = P(Y_x|Z)\]

  \begin{itemize}
  \tightlist
  \item
    Implies that \(P(Y_x = y)\) is identifiable by adjustment formula of
    Eq. (3.5)

    \begin{equation*}
      \begin{split}
    PY_x = y) &= \sum\limits_z P(Y_x = y|Z = z)P(z) \\
              &=  \sum\limits_z P(Y_x = y|Z = z, X = x) P(z) \\
              &= \sum\limits_z P(Y = y|Z = z, X = x)P(z)
      \end{split}
    \end{equation*}
  \end{itemize}
\end{itemize}

\subsubsection{Counterfactuals in Linear
Models}\label{counterfactuals-in-linear-models}

\begin{itemize}
\item
  In nonparametric models, counterfactual quantities of the form
  \(\mathbb{E}[Y_{X = x} | Z = z]\) may not be identifiable
\item
  However, in fully linear models any counterfactual quanitity is
  identifiable whenever the model parameters are identified
\item
  Question: Can counterfactuals be identified in observasional studies
  when some of the model parameters are not identified?

  \begin{itemize}
  \tightlist
  \item
    Yes!
  \item
    Any counterfactual of the form \(\mathbb{E}[Y_{X = x} | Z = e]\)
    where \(e\) is an arbitrary set of evidence, is identified whenever
    \(\mathbb{E}[Y|do(X = x)]\) is identified
  \end{itemize}
\item
  \(\textbf{Theorem 4.3.2}\): Let \(\tau\) be the slope of the total
  effect of \(X\) on \(Y\),
  \[\tau = \mathbb{E}[Y|do(x+1)] - \mathbb{E}[Y|do(x)]\] then, for any
  evidence \(Z = e\), we have
  \[\mathbb{E}[Y_{X = x}|Z = e] = \mathbb{E}[Y|Z = e] + \tau(x - \mathbb{E}[X|Z = e])\]
\item
  Recall situation in Fig 4.2 (p.~95) where the counterfactual
  \(Y_{H=2}\) under the evidence \(e=\{X = 0.5, H = 1, Y = 1\}\) was
  computed. Theorem 4.3.2 can be applied to this model to comptue the
  \emph{effect} \emph{of} \emph{treatment} \emph{on} \emph{the}
  \emph{treated}: \[ETT = \mathbb{E}[Y_1 - Y_0 | X = 1]\] Substituting
  the evidence \(e = \{X = 1\}\) into Theorem 4.3.2 (refer to model
  4.1):

  \begin{equation*}
    \begin{split}
  ETT &= \mathbb{E}[Y_1 | X = 1] - \mathbb{E}[Y_0|X = 1] \\
  &= \mathbb{E}[Y|X = 1] - E[Y|X = 1] + \tau(1 - \mathbb{E}[X|X=1]) - \tau(0 - \mathbb{E}[X|X=1]) \\
  &= \mathbb{E}[Y|do(x+1)] - \mathbb{E}[Y|do(x)] \\
  &= \tau \\
  &= b + ac \\
  &= 0.9
    \end{split}
  \end{equation*}
\end{itemize}

\subsection{Practical Uses of
Counterfactuals}\label{practical-uses-of-counterfactuals}

\subsubsection{Recruitment to a Program}\label{recruitment-to-a-program}

\begin{itemize}
\item
  Example 4.4.1 (p.107)
\item
  Critics claim program is a waste of taxpayer's money and should be
  terminated, why?

  \begin{itemize}
  \tightlist
  \item
    Reasoning: While program was successful in experimental study, where
    people chosen at random, there is no proof the program is successful
    among those choosing to enroll of their own volition
  \item
    Critis say those enrolling are more intelligent, resourceful and
    socially connected than those who are eligible and did not enroll
  \item
    Critics claim that we need to estimate the \emph{differential}
    benefit of the program on those enrolled: the extent to which hiring
    rate has increasing among the enrolled, compared to what it would
    have been had they not been trained.
  \end{itemize}
\item
  Using counterfactual notation, letting \(X = 1\) represent trianing,
  and \(Y = 1\) represent hiring, we need to evaluate ETT (p.106 Eq.
  4.18), that is \(ETT = \mathbb{E}[Y_1 - Y_0|X = ]\)

  \begin{itemize}
  \tightlist
  \item
    Unfortunately the difference \(Y_1 - Y_0\) represents the causal
    effect of trianing \((X)\) on hiring \((Y)\) for a \emph{randomly}
    chosen individual, and the condition \(X = 1\) limits the choice to
    those who actually chose the training on their own
  \item
    This is a clash between the antecedent \((X = 0)\) of the
    counterfactual \(Y_0\) and the event it is condition on \(X = 1\)
  \item
    \(\mathbb{E}[Y_0 | X = 1]\) can be reduced to estimable expressions
    in many situations (not all)
  \end{itemize}
\item
  When a set \(Z\) of covariates satisfies the backdoor criterion with
  regard to the treatment and outcome variables, ETT probabilities are
  given by a modified adjustment formula:

  \begin{equation}\label{eq:4.21}
  P(Y_x = y| X = x') = \sum\limits_z P(Y = y|X = x, Z = z)P(Z = z|X = x')
  \end{equation}
\item
  Comparing to standard adjustment formula
  \(P(Y = y| do(X = x)) = \sum P(Y = y|X = x, Z = z)P(Z =z)\) both
  formulas require conditioning on \((Z = z)\) then averaging over \(z\)
  with modified adjustment formula using a different weighted average
\item
  Using the modified adjustment formula we cna get an estimable,
  noncounterfactual expression for ETT

  \begin{equation*}
    \begin{split}
  ETT &= \mathbb{E}[Y_1 - Y_0|X = 1] \\
  &= \mathbb{E}[Y_1| X = 1] - \mathbb{E}[Y_0|X = 1] \\
  &= \mathbb{E}[Y|X = 1] - \sum\limits_z \mathbb{E}[Y|X=0, Z = z]P(Z = z|X = 1)
    \end{split}
  \end{equation*}

  \begin{itemize}
  \tightlist
  \item
    \(\mathbb{E}[Y_1|X = 1] = \mathbb{E}[Y|X=1]\) because conditional on
    \(X = 1\), the value that \(Y\) would get had \(X\) been 1 is just
    the observed value of \(Y\)
  \end{itemize}
\end{itemize}

\subsubsection{Additive Interventions}\label{additive-interventions}

\begin{itemize}
\item
  Example 4.4.2 (p.109)
\item
  Suppose we add a quanity \(q\) to a treatment variable \(X\) that is
  currently at level \(X = x'\). The resulting outcome would be
  \(Y_{x' + q}\), and the average value of this outcome over all units
  currently at level \(X = x'\) would be \(\mathbb{E}[Y_x|x']\) with
  \(x = x' + q\).
\item
  Whenever a set \(Z\) in our model satisfies the backdoor criterion,
  the effect of an additive intervention is estimable using the ETT
  adjustment formula Eq.(\ref{eq:4.21}). Substituting in \(x = x' + q\)
  and taking expectations gives effect of this intervention called
  \(add(q)\):

  \begin{equation*}
    \begin{split}
  \mathbb{E}[Y|add(q)] - \mathbb{E}[Y] &= \sum\limits_{x'} \mathbb{E}[Y_{x' + q}|X = x']P(x') - \mathbb{E}{Y} \\
  &= \sum\limits_{x'} \sum\limits_z \mathbb{E}[Y|X = x' + q, Z = z]P(Z = z|X = x')P(X = x') - \mathbb{E}[Y]
    \end{split}
  \end{equation*}
\item
  \(Z\) my include whichever variables so long as each can be measured
  and together they satisfy the backdoor condition
\end{itemize}

\subsubsection{Personal Decision Making}\label{personal-decision-making}

\begin{itemize}
\item
  Example 4.4.3 (p.111)
\item
  Designating remission by \(Y = 1\) and decision to undergo radiation
  by \(X = 1\), the probability that determines whether Ms.~Jones is
  justified in attributing her remission to the irradiation \((X = 1)\)
  is \[PN = P(Y_0 = 0 | X = 1, Y = 1)\]

  \begin{itemize}
  \tightlist
  \item
    It reads: the probability that remission would \emph{not} have
    occurred \((Y = 0)\) had Ms.~Jones not gone through irradiation,
    given that she did in fact go through irradiation \((X = 1)\), and
    remission did occur \((Y = 1)\)
  \item
    The label PN stands for `probability of necessity' and it measures
    the degree to which Ms Jones' decision was \emph{necessary} for her
    positive outcome
  \end{itemize}
\item
  Similarly, the probability that Ms.~Smith's regret is justified is
  given by \[PS = P(Y_1 = 1 | X = 0, Y = 0)\]

  \begin{itemize}
  \tightlist
  \item
    It reads: the probability that remission would have occurred had
    Ms.~Smith gone through irradiation \((Y_1 = 1)\), given that she did
    not in fact go through irradiation \((X = 0)\), and remission did
    not occur \((Y = 0)\)
  \item
    PS stands for the `probability of sufficiency', and it measures the
    degree to which the action not taken, \((X = 1)\), would have been
    sufficient for her recovery
  \end{itemize}
\item
  These probabilities, sometimes referred to as `probabilities of
  causation', are not, in general, estimable from either observational
  or experimental data

  \begin{itemize}
  \tightlist
  \item
    However, under certain conditions they \emph{are} estimable when
    both observational and experimental data are available.
  \end{itemize}
\item
  Imagine Ms.~Daily facing the same decision as Ms.~Jones and asking
  herself: If tumor is type that would not recur under lumpectomy alone,
  why go through irradiation? Similarly, if tumor is type that would
  recur regardless of irradiation treatment, why go through
  irradiation?'

  \begin{itemize}
  \tightlist
  \item
    Only go through radiation if tumor is type that would remiss under
    treatment and recur under no treatment
  \end{itemize}
\item
  Ms.~Daily's dilemma is to quantify the probability that irradiation is
  both \emph{necessary} \emph{and} \emph{sufficient} for eliminating her
  tumor, \[PNS = P(Y_1 = 1, Y_0 = 0)\]

  \begin{itemize}
  \tightlist
  \item
    where \(Y_1\) and \(Y_0\) stand for remission under treatment
    \((Y_1)\), and nontreatment \((Y_0)\)
  \item
    This probability cannot be assessed from experimental studies
  \item
    PNS \emph{can} be estimated if we assume \emph{monotonicity}, namely
    that irradiation cannot cause the recurrence of a tumor that was
    about to remit
  \item
    Under monotonicity experimental data are sufficient to conclude
    \$\$PNS = P(Y = 1\textbar{}do(X = 1)) - P(Y = 1\textbar{}do(X = 0))
  \end{itemize}
\end{itemize}

\subsubsection{Mediation and Path-disabling
Interventions}\label{mediation-and-path-disabling-interventions}

\begin{itemize}
\item
  Example 4.4.5 (p.~114)
\item
  Because we are dealing with disabling processes rather than changing
  levels of variables, there is no way we can express the effect of such
  interventions using a \emph{do}-operator
\item
  We can express it in counterfactual notation
\item
  The hiring status \((Y=1)\) of a female applicant with qualification
  \(Q = q\), given that the employer treats her as though she is a male
  is captured by the counterfactual \(Y_{X = 1, Q = q}\) where \(X = 1\)
  refers to being male.

  \begin{itemize}
  \item
    Since value \(q\) would vary among applicants, this quantity must be
    averaged according to the distribution of female qualification
    giving \[\sum\limits_q \mathbb{E}[Y_{X=1, Q = q}]P(Q = q|X = 0)\]
  \item
    Similarly, male applicants chance at hiring has average governed by
    the male qualification
    \[\sum\limits_q \mathbb{E}[Y_{X=1, Q = q}]P(Q = q|X = 1)\]
  \item
    Subtracting the two quantities gives
    \[\sum\limits_q \mathbb{E}[Y_{X=1, Q = q}][P(Q = q|X = 0)- P(Q = q|X = 1)]\]
    which is the indirect effect of gender on hiring, \emph{mediated}
    \emph{by} \emph{qualification}.

    \begin{itemize}
    \tightlist
    \item
      This effect is called the natural indirect effect (NIE), because
      qualification \(Q\) is allowed to naturally vary from applicant to
      applicant
    \end{itemize}
  \end{itemize}
\item
  Can such a counterfactual expression be identified from data?

  \begin{itemize}
  \item
    Yes! In absense of confounding, the NIE can be estimated by
    conditional probabilities
  \item
    \begin{equation*}
    NIE = \sum\limits_q \mathbb{E}[Y|X = 1, Q = q][P(Q = q|X = 0) - P(Q = q|X = 1)]
      \end{equation*}
  \item
    Expression is known as the \emph{mediation} \emph{formula}, and
    measures the extent to which the effect of \(X\) on \(Y\) is
    \emph{explained} by its effect on the mediator \(Q\)
  \end{itemize}
\end{itemize}

\subsection{Mathematical Tool Kits for Attribution and
Mediation}\label{mathematical-tool-kits-for-attribution-and-mediation}

\subsubsection{A Tool Kit for Attribution and Probabilities of
Causation}\label{a-tool-kit-for-attribution-and-probabilities-of-causation}

\begin{itemize}
\item
  Assuming binary events, with \(X = x\) and \(Y = y\) representing
  treatment and outcome, respectively, and \(X = x'\), \(Y = y'\) their
  negations, our target quantity can be defined as:

  \begin{itemize}
  \tightlist
  \item
    `Find the probability that if \(X\) had been \(x'\), \(Y\) would be
    \(y'\), given that in reality \(X = x\) and \(Y = y\).'
  \item
    Mathematically, this is \[PN(x,y) = P(Y_{x'} = y' | X = x, Y = y)\],
    and called the `probability of necessity'
  \item
    Question: What assumptions permit us to identify \(PN\) from
    empirical studies (observational and/or experimental)?
  \end{itemize}
\item
  \(\textbf{Theorem 4.5.1}\): If \(Y\) is monotonic relative to \(X\),
  that is, \(Y_1(u) \geq Y_0(u)\) \(\forall u\), then \(PN\) is
  identifiable whenever the causal effect \(P(y|do(x))\) is
  identifiable, and

  \begin{equation}
  PN = \frac{P(y) - P(y|do(x'))}{P(x,y)} \quad \quad \quad (4.28)
  \end{equation}

  or, substituting \(P(y) = P(y|x)P(x) + P(y|x')(1 - P(x))\), we obtain

  \begin{equation}
  PN = \frac{P(y|x) - P(y|x')}{P(y|x)} + \frac{P(y|x') - P(y|do(x'))}{P(x,y)} \quad \quad \quad (4.29)
  \end{equation}

  \begin{itemize}
  \tightlist
  \item
    First term on r.h.s. is called \emph{excess} \emph{risk}
    \emph{ratio} (ERR)
  \item
    Second term (the confounding factor) represents a \emph{correction}
    needed to account for confounding bias since
    \(P(y|do(x')) \neq P(y|x')\).
  \end{itemize}
\item
  Example: Suppose there is a case brought against a car manufacturer,
  claiming that its car's faulty design led to a man's death in a car
  crash. The ERR teslls us how much more likely poeple are to die in
  crashes when driving one of the manufacturer's cars. If it turns out
  that people who buy the manufacturer's cares are more likely to drive
  faster than the general poipulation, the second term will correct for
  this bias.
\item
  Eq.(4.29) provides an estimable measure of necessary causation which
  can be used for monotinic \(Y_x(u)\) whenever the causal effect
  \(P(y|do(x))\) can be estimated.
\item
  Eq.(4.28) provides bounds for \(PN\) in the general
  \emph{nonmonotonic} case
  \[max \{ 0, \frac{P(y) - P(y|do(x'))}{P(x,y)} \} \leq PN \leq min \{ 1, \frac{P(y'|do(x')) - P(x', y')}{P(x,y)} \} \]

  \begin{itemize}
  \tightlist
  \item
    LB = ERR + CF
  \item
    UB = ERR + q + CF
  \item
    where

    \begin{equation}
      \begin{split}
    CF &\triangleq \frac{P(y|x') - P(y_{x'})}{P(x,y)} \\
    ERR &\triangleq 1 - \frac{1}{RR} = 1 - \frac{P(y|x')}{P(y|x)} \\
    q &\triangleq \frac{P(y'|x)}{P(y|x)}
      \end{split}
    \end{equation}
  \item
    \(CF\) represents the normalized degree of confounding among the
    unexposed \((X = x')\)
  \item
    \(ERR\) is the `excess risk ratio'
  \item
    \(q\) is the ratio of negative to positive outcomes among the
    exposed.
  \end{itemize}
\item
  If it is the case that the experimental and survey data have been
  drawn at random from the same population, then the experimental data
  can be used to esetimate the counterfactuals of interest, for example
  \(P(Y_x = y)\) for the observational as well as experimental sampled
  populations.
\item
  Example 4.5.1 (p.119)
\end{itemize}

\subsubsection{A Tool Kit for Mediation}\label{a-tool-kit-for-mediation}

\begin{itemize}
\item
  Recall mediation (p.75)
\item
  Canonical problem for a typical mediation problem takes the form:
  \[t = f_T(u_T) \quad m = f_M(t, u_M) \quad y = f_Y(t, m, u_Y)\] where
  \(T\) is treatment, \(M\) is mediator, and \(Y\) is outcome.
  \(U_T, U_M, U_Y\) represent omitted factors influencing \(T<M<Y\).
\item
  Figure 4.6 (p.121)
\item
  \(\textbf{Counterfactual definition of direct and indirect effects}\)

  \begin{enumerate}
  \def\labelenumi{\alph{enumi})}
  \item
    \(\textbf{Total Effect}\):
    \(TE = \mathbb{E}[Y_1 - Y_0] = \mathbb{E}[Y|do(T=1)] - \mathbb{E}[Y|do(T = 0)]\)

    \begin{itemize}
    \tightlist
    \item
      TE measures the expected increase in \(Y\) as the treatment
      changes from \(T = 0\) to \(T = 1\), while the mediator is allowed
      to track the change in \(T\) naturally
    \end{itemize}
  \item
    \(\textbf{Controlled Direct Effect}\):
    \(CDE(m) = \mathbb{E}[Y_{1,m} - Y_{0,m}] = \mathbb{E}[Y|do(T = 1, M = m)] - \mathbb{E}[Y|do(T = 0, M = m)]\)

    \begin{itemize}
    \tightlist
    \item
      CDE measures the expected increase in \(Y\) as the treatment
      changes from \(T = 0\) to \(T = 1\), while the mediator is set to
      a specified level \(M = m\) uniformly over the entire population
    \end{itemize}
  \item
    \(\textbf{Natural Direct Effect}\):
    \(NDE = \mathbb{E}[Y_{1, M_0} - Y_{0, M_0}]\)

    \begin{itemize}
    \tightlist
    \item
      NDE measures the expected increase in \(Y\) as the treatment
      changes from \(T = 0\) to \(T = 1\), while the mediator is set to
      whatever value it \emph{would} \emph{have} \emph{attained} prior
      to the change
    \end{itemize}
  \item
    \(\textbf{Natural Indirect Effect}\):
    \(NIE = \mathbb{E}[Y_{0, M_1} - Y_{0, M_0}]\)

    \begin{itemize}
    \tightlist
    \item
      NIE measures the expected increase in \(Y\) when the treatment is
      held constant, \(T = 0\), and \(M\) changes to whatever value it
      would have attained under \(T = 1\)
    \end{itemize}
  \end{enumerate}
\item
  \(TE = NDE - NIE_r \quad \quad (4.48)\)

  \begin{itemize}
  \tightlist
  \item
    \(NIE_r\) stands for \(NIE\) under reverse transition, from
    \(T = 1\) to \(T = 0\)
  \item
    In linear systems, reversal of transitions amounts to negating the
    signs of their effects giving \($TE = NDE + NIE\)
  \end{itemize}
\item
  \(\textbf{Conditions for identifying natural effects}\):

  \begin{itemize}
  \tightlist
  \item
    Following conditions are sufficient for identifying both direct and
    indirect natural effects. We can identify the \(NDE\) and \(NIE\)
    provided there exists a set \(W\) of measured covariates such that:
  \end{itemize}

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi})}
  \tightlist
  \item
    No member of \(W\) is a descendant of \(T\)
  \item
    \(W\) blocks all backdoor paths from \(M\) to \(Y\) (after removing
    \(T \rightarrow M\) and \(T \rightarrow Y\))
  \item
    The \(W\)-specific effect of \(T\) on \(M\) is identifiable
    (possibly using experiments or adjustments)
  \item
    The \(W\)-specific joint effect of \(\{T, M\}\) on \(Y\) is
    identifiable (possibly using experiments or adjustments)
  \end{enumerate}
\item
  \(\textbf{Theorem 4.5.2: Identification of the NDE}\): When conditions
  1) and 2) hold, the natural direct effect is experimentally
  identifiable and is given by
  \[NDE = \sum\limits_m \sum\limits_w [\mathbb{E}[Y|do(T=1, M = m), W = w] - \mathbb{E}[Y|do(T = 0, M = m), W = w]] \times \\ P(M = m|do(T = 0), W = w)P(W = w) \quad \quad (4.49)\].
  The identifiability of the do-expressions in EQ. (4.49) is guaranteed
  by conditions 3) and 4) and can be determined using the backdoor or
  front-door criteria.
\item
  \(\textbf{Corollary 4.5.1}\): If conditions 1) and 2) are satisfied by
  a set \(W\) that also deconfounds the relationships in 3) and 4), then
  the do-expressions in Eq. (4.49) are reducible to conditional
  expectations, and the natural direct effect becomes
  \[NDE = \sum\limits_m \sum\limits_w [\mathbb{E}[Y|T = 1, M = m, W = w] - \mathbb{E}[Y|T = 0, M = m, W = w]] \\ \times P(M = m|T = 0, W = w)P(W = w) \quad (4.50)\]
  In the nonconfounding case (Fig. 4.6(a)), \(NDE\) reduces to
  \[NDE = \sum\limits_m [\mathbb{E}[Y|T = 1, M = m] - \mathbb{E}[Y|T = 0, M = m]]P(M = m|T = 0) \quad \quad (4.51)\]
  Similarly, using \((4.48)\), and
  \(TE = \mathbb{E}[Y|X = 1] - \mathbb{E}[Y|X = 0]\),
  \[NIE = \sum\limits_m \mathbb{E}[Y|T = 0, M = m][P(M = m|T = 1) - P(M = m|T = 0)] \quad \quad (4.52)\]
\item
  Last two expressions known as \emph{mediation} \emph{formulas}
\item
  Counterfactual definitions of \(NDE\) and \(NIE\) give effects
  meaningful interpretations in terms of `response fractions'

  \begin{itemize}
  \tightlist
  \item
    \(\frac{NDE}{TE}\): measures fraction of the response that is
    transmitted direction with \(M\) `frozen'
  \item
    \(\frac{NIE}{TE}\): measures fraction of the response that may be
    transmitted through \(M\), with \(Y\) blinded to \(X\)
  \item
    \(\frac{TE - NDE}{TE}\): measures fraction of the respo;nse that is
    necessarily due to \(M\)
  \end{itemize}
\item
  Example p.~123

  \begin{itemize}
  \item
    Encouragement Design (p.95)

    \begin{itemize}
    \tightlist
    \item
      \(T = 1\) stands for participation in enhanced training program
    \item
      \(Y=1\) stands for passing the exam
    \item
      \(M=1\) stands for student spending more than 3 hours per week on
      homework
    \item
      Data Tables 4.6 and 4.7
    \item
      Research question: To what extent does students' homework
      contribute to their increased success rate regardless of the
      training program?
    \end{itemize}
  \end{itemize}
\item
  Substituting the data into Eqs. (4.51) and (4.52):

  \begin{itemize}
  \item
    \begin{equation}
    \begin{split}
      NDE &= [\mathbb{E}[Y|T = 1, M = 0] - \mathbb{E}[Y|T = 0, M = 0]]P(M = 0|T = 0) + [\mathbb{E}[Y|T = 1, M = 1] - \mathbb{E}[Y|T = 0, M = 1]]P(M = 1|T = 0) \\
      &= (0.4 - 0.2)\times(1 - 0.4) + (0.8 - 0.3)\times 0.4 = 0.32
    \end{split}
    \end{equation}
  \item
    \begin{equation}
    \begin{split}
    NIE &= \mathbb{E}[Y|T=0, M = 0][P(M=0|T=1) - P(M=0|T=0)] + \mathbb{E}[Y|T=0, M = 1][P(M=1|T=1) - P(M=1|T=0)]  \\
    &= (0.75 - 0.4)(0.30-0.20) = 0.035
    \end{split}
    \end{equation}
  \item
    \begin{equation}
    \begin{split}
    TE &= \mathbb{E}[Y|do(T=1)] - \mathbb{E}[Y|do(T = 0)] \\
       &= (0.80 \times 0.75 + 0.40 \times 0.25) - (0.30 \times 0.40 + 0.20 \times 0.60) = 0.46
     \end{split}
     \end{equation}
  \item
    \(\frac{NIE}{TE} = 0.07\)
  \item
    \(\frac{NDE}{TE} = 0.696\)
  \item
    \(1 - \frac{NDE}{TE} = 0.304\)
  \end{itemize}
\item
  Conclude program as a whole increased success rate by \(46\%\)
\item
  Of the \(46\%\) increase, \(30.4\%\) is due to the capacity of program
  to stimulate improved homework
\item
  Only \(7\%\) of increase can be explained by stimulated homework alone
  \emph{without} the benefit of program
\end{itemize}


\end{document}
